{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Livrable 2 - Image processing\n",
    "\n",
    "## The subject\n",
    "The goal is to process a set of photographs by denoising them in order to make them better processable by Machine Learning algorithms. In this Jupyter notebook we will explain the pre-processing steps. The algorithms will rely on convolutional auto-encoders, and apply them to improve the image quality."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Disable Tensorflow's warnings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "RUN_DIR = 'tf/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "from keras_preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Global Variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BATCH_SIZE: int = 64\n",
    "IMG_HEIGHT: int = 228\n",
    "IMG_WIDTH: int = 228\n",
    "EPOCHS: int = 10\n",
    "NO_NOISY_DATASET_PATH: str = RUN_DIR + 'data_ae/no_noisy'\n",
    "NOISY_DATASET_PATH: str = RUN_DIR + 'data_ae/noisy'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    data_format=\"channels_last\",\n",
    "    validation_split=0.20\n",
    ")\n",
    "\n",
    "# Train\n",
    "train_data = datagen.flow_from_directory(\n",
    "    RUN_DIR + '/data_ae/no_noisy',\n",
    "    subset='training',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    ").next()\n",
    "\n",
    "# Train noisy\n",
    "train_noisy_data = datagen.flow_from_directory(\n",
    "    RUN_DIR + '/data_ae/noisy',\n",
    "    subset='training',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    ").next()\n",
    "\n",
    "# Test\n",
    "test_data = datagen.flow_from_directory(\n",
    "    RUN_DIR + '/data_ae/no_noisy',\n",
    "    subset='validation',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    ").next()\n",
    "\n",
    "# Test noisy\n",
    "test_noisy_data = datagen.flow_from_directory(\n",
    "    RUN_DIR + '/data_ae/noisy',\n",
    "    subset='validation',\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    ").next()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementation of functions to display the images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def display_single_image(img):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def display_image(x, n):\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(np.array(x[i]), vmax=1)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print an image of both datasets for testing\n",
    "img = image.image_utils.load_img(NO_NOISY_DATASET_PATH + '/training/photo/photo_0003.jpg')\n",
    "img_noisy = image.image_utils.load_img(NOISY_DATASET_PATH + '/training/photo/photo_0003.jpg')\n",
    "\n",
    "display_single_image(np.array(img))\n",
    "display_single_image(np.array(img_noisy))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Training set\")\n",
    "display_image(train_data, 5)\n",
    "print(\"Noisy training set\")\n",
    "display_image(train_noisy_data, 5)\n",
    "\n",
    "print(\"Validation Set\")\n",
    "display_image(test_data, 5)\n",
    "print(\"Noisy validation set\")\n",
    "display_image(test_noisy_data, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Encoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "encoder = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(inputs)\n",
    "encoder = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(encoder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decoder = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(\n",
    "    encoder)\n",
    "decoder = tf.keras.layers.UpSampling2D((2, 2))(decoder)\n",
    "decoder = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(\n",
    "    decoder)\n",
    "decoder = tf.keras.layers.UpSampling2D((2, 2))(decoder)\n",
    "decoder = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=(3, 3), activation='sigmoid', padding='same')(\n",
    "    decoder)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Auto encoder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_encoder = tf.keras.Model(inputs, decoder, name=\"auto_encoder\")\n",
    "\n",
    "auto_encoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the best model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filename = RUN_DIR + \"models/best_model.h5\"\n",
    "callback_best_model = tf.keras.callbacks.ModelCheckpoint(filepath=filename, verbose=0, save_best_only=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_encoder.summary()\n",
    "\n",
    "history = auto_encoder.fit(train_noisy_data, train_data,\n",
    "                           batch_size=BATCH_SIZE,\n",
    "                           epochs=EPOCHS,\n",
    "                           verbose=1,\n",
    "                           shuffle=True,\n",
    "                           validation_data=(test_data, test_noisy_data),\n",
    "                           #callbacks=[callback_best_model]\n",
    "                           )"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
