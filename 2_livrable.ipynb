{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Livrable 2 - Image processing\n",
    "\n",
    "## The subject\n",
    "The goal is to process a set of photographs by denoising them in order to make them better processable by Machine Learning algorithms. In this Jupyter notebook we will explain the pre-processing steps. The algorithms will rely on convolutional auto-encoders, and apply them to improve the image quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Disable Tensorflow's warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "RUN_DIR = 'tf/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.utils import load_img, img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.util import random_noise\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE: int = 34\n",
    "IMG_HEIGHT: int = 228\n",
    "IMG_WIDTH: int = 228\n",
    "EPOCHS: int = 20\n",
    "ZIP_PATH: str = 'https://raw.githubusercontent.com/Stan-fld/auto_encoder_data/main/data_ae.zip'\n",
    "DATASET_PATH: str = RUN_DIR + 'data_ae'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Progress bar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def progressbar(it, prefix=\"\", size=60, file=sys.stdout):\n",
    "    count = len(it)\n",
    "\n",
    "    def show(j):\n",
    "        x = int(size * j / count)\n",
    "        file.write(\"%s[%s%s] %i/%i\\r\" % (prefix, \"#\" * x, \".\" * (size - x), j, count))\n",
    "        file.flush()\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "    show(0)\n",
    "    for i, item in enumerate(it):\n",
    "        yield item\n",
    "        show(i + 1)\n",
    "    file.flush()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import dataset from github"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "http_response = urlopen(ZIP_PATH)\n",
    "zipfile = ZipFile(BytesIO(http_response.read()))\n",
    "zipfile.extractall(path=f'{RUN_DIR}data_ae')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normal datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_images_as_array(folder_dir, name):\n",
    "    images = []\n",
    "    for img in progressbar(os.listdir(folder_dir), f'Generate dataset {name} : ', 50):\n",
    "        time.sleep(0.1)\n",
    "        if img.endswith(\".jpg\"):\n",
    "            image = load_img(f\"{folder_dir}/{img}\", target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "            images.append(img_to_array(image))\n",
    "    return np.array(images) / 255\n",
    "\n",
    "\n",
    "# Train\n",
    "train_data = get_images_as_array(DATASET_PATH + '/training', 'training')\n",
    "# Validation\n",
    "val_data = get_images_as_array(DATASET_PATH + '/validation', 'validation')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Noisy datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def noisy_gauss(images, name):\n",
    "    noisy_images = []\n",
    "    for image in progressbar(images, f'Generate dataset {name} : ', 50):\n",
    "        image = random_noise(image, mode='gaussian', mean=0, var=0.3)\n",
    "        image = random_noise(image, mode='s&p', amount=0.2, salt_vs_pepper=0.5)\n",
    "        image = random_noise(image, mode='poisson')\n",
    "        image = random_noise(image, mode='speckle', mean=0, var=0.1)\n",
    "        noisy_images.append(image)\n",
    "    return np.array(noisy_images)\n",
    "\n",
    "\n",
    "# Train noisy\n",
    "train_noisy_data = noisy_gauss(train_data.copy(), 'training noisy')\n",
    "\n",
    "# Validation noisy\n",
    "val_noisy_data = noisy_gauss(val_data.copy(), 'validation noisy')\n",
    "\n",
    "x_train = train_noisy_data\n",
    "y_train = train_data\n",
    "\n",
    "x_val = val_noisy_data\n",
    "y_val = val_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Implementation of functions to display the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_single_image(img):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def display_image(x, n):\n",
    "    plt.figure(figsize=(20, 2))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(np.array(x[i]), vmax=1)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Print an image of both datasets for testing\n",
    "display_single_image(y_train[0])\n",
    "display_single_image(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Training set\")\n",
    "display_image(y_train, 5)\n",
    "print(\"Noisy training set\")\n",
    "display_image(x_train, 5)\n",
    "\n",
    "print(\"Validation Set\")\n",
    "display_image(y_val, 5)\n",
    "print(\"Noisy validation set\")\n",
    "display_image(x_val, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "encoder = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "encoder = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = tf.keras.layers.UpSampling2D((2, 2))(decoder)\n",
    "decoder = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = tf.keras.layers.UpSampling2D((2, 2))(decoder)\n",
    "decoder = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=(3, 3), activation='sigmoid', padding='same')(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auto_encoder = tf.keras.Model(inputs, decoder, name=\"auto_encoder\")\n",
    "\n",
    "auto_encoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = RUN_DIR + \"models/best_model.h5\"\n",
    "callback_best_model = tf.keras.callbacks.ModelCheckpoint(filepath=filename, verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# auto_encoder.summary()\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    history = auto_encoder.fit(x_train, y_train,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               epochs=EPOCHS,\n",
    "                               verbose=1,\n",
    "                               shuffle=True,\n",
    "                               validation_data=(x_val, y_val),\n",
    "                               callbacks=[callback_best_model]\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loss curve"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
