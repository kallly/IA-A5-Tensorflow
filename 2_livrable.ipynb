{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Livrable 2 - Image processing\n",
    "\n",
    "## The subject\n",
    "The goal is to process a set of photographs by denoising them in order to make them better processable by Machine Learning algorithms. In this Jupyter notebook we will explain the pre-processing steps. The algorithms will rely on convolutional auto-encoders, and apply them to improve the image quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Disable Tensorflow's warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "RUN_DIR = 'tf/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE: int = 16\n",
    "IMG_HEIGHT: int = 228\n",
    "IMG_WIDTH: int = 228\n",
    "EPOCHS: int = 40\n",
    "ZIP_PATH: str = 'https://raw.githubusercontent.com/Stan-fld/auto_encoder_data/main/data_ae.zip'\n",
    "DATASET_PATH: str = RUN_DIR + 'data_ae'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Import dataset from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "http_response = urlopen(ZIP_PATH)\n",
    "zipfile = ZipFile(BytesIO(http_response.read()))\n",
    "zipfile.extractall(path=f'{RUN_DIR}data_ae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Normal datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "train_data = tf.keras.utils.image_dataset_from_directory(f'{RUN_DIR}data_ae/training/',\n",
    "                                                         image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                         batch_size=BATCH_SIZE)\n",
    "\n",
    "# Train\n",
    "val_data = tf.keras.utils.image_dataset_from_directory(f'{RUN_DIR}data_ae/validation/',\n",
    "                                                       image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                       batch_size=BATCH_SIZE)\n",
    "\n",
    "# Transforming BatchDataset into array \n",
    "train_data = np.concatenate(list(train_data.map(lambda x, y: x)))\n",
    "val_data = np.concatenate(list(val_data.map(lambda x, y: x)))\n",
    "train_data = train_data.astype('float32') / 255.\n",
    "val_data = val_data.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Noisy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = train_data\n",
    "\n",
    "y_val = val_data\n",
    "\n",
    "noise_factor = 0.2\n",
    "x_train = train_data + noise_factor * np.random.normal(size=train_data.shape)  #A COMPLETER\n",
    "x_val = val_data + noise_factor * np.random.normal(size=val_data.shape)  #A COMPLETER\n",
    "\n",
    "x_train = np.clip(x_train, 0., 1.)\n",
    "x_val = np.clip(x_val, 0., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Implementation of functions to display the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_single_image(img):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def display_image(x, n):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(np.array(x[i]), vmax=1)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Print an image of both datasets for testing\n",
    "display_single_image(y_train[0])\n",
    "display_single_image(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Training set\")\n",
    "display_image(y_train, 5)\n",
    "print(\"Noisy training set\")\n",
    "display_image(x_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "encoder = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "encoder = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "encoder = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoder)\n",
    "encoder = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(encoder)\n",
    "decoder = tf.keras.layers.UpSampling2D((2, 2))(decoder)\n",
    "decoder = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(decoder)\n",
    "decoder = tf.keras.layers.UpSampling2D((2, 2))(decoder)\n",
    "\n",
    "decoder = tf.keras.layers.Conv2DTranspose(filters=3, kernel_size=(3, 3), activation='sigmoid', padding='same')(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Auto encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plusieurs choix sont possibles pour la fonction de coût de l'autoencoder. Dans notre cas nous voulons débruiter les images nous avons choisi d'implémenter une fonction de coût calculant la différence entre les images ici le `DSSIM` afin d'augmenter les performances du débruitage. L'optimizer adam est un des optimiseurs les plus utilisés. Il permet une convergence rapide, ce qui réduit le temps d'entrainement. Nous pouvons notamment changer le learning_rate pour influer sur sa vitesse de convergence. Nous n'avons pas sélectionner de metrics pour comparer nos images. Seulement le score `DSSIM` qui est notre fonction loss."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def ssim_accuracy(y_true, y_pred):\n",
    "    return tf.image.ssim(y_true, y_pred, 1.0)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "auto_encoder = tf.keras.Model(inputs, decoder, name=\"auto_encoder\")\n",
    "auto_encoder.compile(optimizer=optimizer, loss=loss, metrics=[ssim_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = RUN_DIR + \"models/best_model.h5\"\n",
    "callback_best_model = tf.keras.callbacks.ModelCheckpoint(filepath=filename, verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# auto_encoder.summary()\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    history = auto_encoder.fit(x_train, y_train,\n",
    "                               batch_size=BATCH_SIZE,\n",
    "                               epochs=EPOCHS,\n",
    "                               verbose=1,\n",
    "                               shuffle=True,\n",
    "                               validation_data=(x_val, y_val),\n",
    "                               callbacks=[callback_best_model]\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(EPOCHS)\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_images = auto_encoder.predict(x_val)\n",
    "display_image(x_val, n=5)\n",
    "display_image(decoded_images, n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date: datetime = datetime.datetime.now().strftime(\"%m.%d.%Y_%H:%M:%S\")\n",
    "model_dir: str = f\"models/autoenc_{date}\"\n",
    "auto_encoder.save(model_dir)\n",
    "f = open(f\"{model_dir}/model_summary.txt\", \"a\")\n",
    "auto_encoder.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "f.close()\n",
    "\n",
    "f = open(f\"{model_dir}/model_history.csv\", \"a\")\n",
    "f.write(pd.DataFrame.from_dict(history.history).to_csv(index=False))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
